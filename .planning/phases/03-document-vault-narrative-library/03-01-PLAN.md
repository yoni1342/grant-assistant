---
phase: 03-document-vault-narrative-library
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - package.json
  - package-lock.json
  - lib/supabase/storage.ts
  - app/(dashboard)/documents/actions.ts
autonomous: true

must_haves:
  truths:
    - "Tiptap, TanStack Table, and new shadcn components are installed and available for import"
    - "Supabase Storage bucket 'documents' exists with RLS policies for authenticated upload/view/delete"
    - "Server action can upload a file to Supabase Storage, insert metadata in documents table, and rollback on failure"
    - "Server action can delete a document from both Storage and the documents table"
    - "Storage helper can generate signed URLs for private document downloads"
  artifacts:
    - path: "lib/supabase/storage.ts"
      provides: "Storage helper functions (upload, delete, getSignedUrl)"
      exports: ["uploadFile", "deleteFile", "getDocumentSignedUrl"]
    - path: "app/(dashboard)/documents/actions.ts"
      provides: "Document CRUD server actions"
      contains: "'use server'"
  key_links:
    - from: "app/(dashboard)/documents/actions.ts"
      to: "lib/supabase/storage.ts"
      via: "import storage helpers"
      pattern: "import.*from.*storage"
    - from: "app/(dashboard)/documents/actions.ts"
      to: "supabase.from('documents')"
      via: "database insert/delete"
      pattern: "\\.from\\(['\"]documents['\"]\\)"
    - from: "lib/supabase/storage.ts"
      to: "supabase.storage.from('documents')"
      via: "storage bucket operations"
      pattern: "storage\\.from\\(['\"]documents['\"]\\)"
---

<objective>
Install all Phase 3 dependencies, create the Supabase Storage bucket with RLS policies, and implement document server actions with storage helper utilities.

Purpose: Establish the infrastructure foundation that both the Document Vault UI (Plan 02) and Narrative Library (Plan 03) depend on. Dependencies must be installed before any UI work can proceed.
Output: Working server actions for document upload/delete, storage helpers for signed URLs, and all npm packages ready for use.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-document-vault-narrative-library/03-RESEARCH.md
@lib/supabase/server.ts
@lib/supabase/client.ts
@lib/supabase/database.types.ts
@app/api/webhook/route.ts
@package.json
</context>

<tasks>

<task type="auto">
  <name>Task 1: Install Phase 3 dependencies and add shadcn components</name>
  <files>package.json, package-lock.json</files>
  <action>
Install all Phase 3 npm dependencies:

```bash
npm install @tiptap/react @tiptap/pm @tiptap/starter-kit @tiptap/extension-placeholder @tanstack/react-table
```

Add missing shadcn/ui components needed for Phase 3 (table and dropdown-menu already exist):

```bash
npx shadcn@latest add textarea --yes
```

Note: `table`, `dropdown-menu`, `dialog`, `select`, `badge`, `input`, `button` already exist from Phase 1-2. The `textarea` component is needed for narrative editing fallback and form fields.

Verify all packages installed correctly by checking `node_modules/@tiptap/react/package.json` and `node_modules/@tanstack/react-table/package.json` exist.
  </action>
  <verify>
Run `npm ls @tiptap/react @tiptap/starter-kit @tiptap/pm @tiptap/extension-placeholder @tanstack/react-table` and confirm all packages resolve without errors. Run `npm run build` to confirm no dependency conflicts.
  </verify>
  <done>All Phase 3 dependencies installed. @tiptap/react, @tiptap/pm, @tiptap/starter-kit, @tiptap/extension-placeholder, and @tanstack/react-table are in package.json and importable. Textarea shadcn component exists at components/ui/textarea.tsx.</done>
</task>

<task type="auto">
  <name>Task 2: Create Storage bucket, storage helpers, and document server actions</name>
  <files>lib/supabase/storage.ts, app/(dashboard)/documents/actions.ts</files>
  <action>
**Step A: Create Supabase Storage bucket with RLS policies**

Use the Supabase MCP `apply_migration` tool to create a migration named `create_documents_storage_bucket`:

```sql
-- Create private storage bucket for documents
INSERT INTO storage.buckets (id, name, public)
VALUES ('documents', 'documents', false)
ON CONFLICT (id) DO NOTHING;

-- RLS: Authenticated users can upload files to their user folder
CREATE POLICY "Users can upload documents"
ON storage.objects
FOR INSERT
TO authenticated
WITH CHECK (
  bucket_id = 'documents' AND
  (storage.foldername(name))[1] = auth.uid()::text
);

-- RLS: Authenticated users can view documents belonging to their org
CREATE POLICY "Users can view org documents"
ON storage.objects
FOR SELECT
TO authenticated
USING (
  bucket_id = 'documents' AND
  EXISTS (
    SELECT 1 FROM public.documents d
    JOIN public.profiles p ON p.org_id = d.org_id
    WHERE d.file_path = name
      AND p.id = auth.uid()
  )
);

-- RLS: Users can delete files they uploaded (owner matches)
CREATE POLICY "Users can delete own documents"
ON storage.objects
FOR DELETE
TO authenticated
USING (
  bucket_id = 'documents' AND
  owner = auth.uid()
);
```

**Step B: Create storage helper utilities**

Create `lib/supabase/storage.ts`:

```typescript
import { createClient } from '@/lib/supabase/server'

/**
 * Upload a file to the documents storage bucket.
 * Returns the file path on success.
 */
export async function uploadFile(
  file: File,
  userId: string
): Promise<{ path: string; error: string | null }> {
  const supabase = await createClient()

  const fileExt = file.name.split('.').pop()
  const fileName = `${userId}/${Date.now()}-${file.name}`

  const { data, error } = await supabase.storage
    .from('documents')
    .upload(fileName, file, {
      contentType: file.type,
      cacheControl: '3600',
      upsert: false,
    })

  if (error) {
    return { path: '', error: error.message }
  }

  return { path: data.path, error: null }
}

/**
 * Delete a file from the documents storage bucket.
 */
export async function deleteFile(
  filePath: string
): Promise<{ error: string | null }> {
  const supabase = await createClient()

  const { error } = await supabase.storage
    .from('documents')
    .remove([filePath])

  return { error: error?.message || null }
}

/**
 * Generate a signed URL for downloading a private document.
 * Default expiry: 1 hour (3600 seconds).
 */
export async function getDocumentSignedUrl(
  filePath: string,
  expiresIn: number = 3600
): Promise<{ url: string; error: string | null }> {
  const supabase = await createClient()

  const { data, error } = await supabase.storage
    .from('documents')
    .createSignedUrl(filePath, expiresIn)

  if (error) {
    return { url: '', error: error.message }
  }

  return { url: data.signedUrl, error: null }
}
```

**Step C: Create document server actions**

Create `app/(dashboard)/documents/actions.ts`:

```typescript
'use server'

import { createClient } from '@/lib/supabase/server'
import { uploadFile, deleteFile } from '@/lib/supabase/storage'
import { revalidatePath } from 'next/cache'

const ALLOWED_TYPES = [
  'application/pdf',
  'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
  'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
  'image/png',
  'image/jpeg',
]

const MAX_FILE_SIZE = 25 * 1024 * 1024 // 25MB

export async function uploadDocument(formData: FormData) {
  const supabase = await createClient()

  const file = formData.get('file') as File
  if (!file || !file.name) {
    return { error: 'No file provided' }
  }

  // Validate file type
  if (!ALLOWED_TYPES.includes(file.type)) {
    return { error: 'Invalid file type. Only PDF, DOCX, XLSX, PNG, and JPG files are allowed.' }
  }

  // Validate file size
  if (file.size > MAX_FILE_SIZE) {
    return { error: 'File too large. Maximum size is 25MB.' }
  }

  // Get authenticated user
  const { data: { user } } = await supabase.auth.getUser()
  if (!user) {
    return { error: 'Not authenticated' }
  }

  // Get user's org_id from profiles
  const { data: profile } = await supabase
    .from('profiles')
    .select('org_id')
    .eq('id', user.id)
    .single()

  if (!profile?.org_id) {
    return { error: 'User profile or organization not found' }
  }

  // Upload file to Storage
  const { path, error: uploadError } = await uploadFile(file, user.id)
  if (uploadError) {
    return { error: uploadError }
  }

  // Insert document metadata into database
  const { data: docData, error: dbError } = await supabase
    .from('documents')
    .insert({
      org_id: profile.org_id,
      name: file.name,
      file_path: path,
      file_type: file.type,
      file_size: file.size,
      category: null,
      ai_category: null,
    })
    .select()
    .single()

  if (dbError) {
    // Rollback: delete uploaded file from storage
    await deleteFile(path)
    return { error: dbError.message }
  }

  // Fire-and-forget: trigger n8n AI categorization webhook
  if (process.env.N8N_WEBHOOK_URL) {
    fetch(`${process.env.N8N_WEBHOOK_URL}/get-documents`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-Webhook-Secret': process.env.N8N_WEBHOOK_SECRET || '',
      },
      body: JSON.stringify({ document_id: docData.id }),
    }).catch((err) => {
      console.error('n8n categorization webhook failed:', err)
    })
  }

  revalidatePath('/documents')
  return { data: docData }
}

export async function deleteDocument(documentId: string) {
  const supabase = await createClient()

  const { data: { user } } = await supabase.auth.getUser()
  if (!user) {
    return { error: 'Not authenticated' }
  }

  // Get document to find file_path
  const { data: doc, error: fetchError } = await supabase
    .from('documents')
    .select('id, file_path, org_id')
    .eq('id', documentId)
    .single()

  if (fetchError || !doc) {
    return { error: 'Document not found' }
  }

  // Delete from storage first
  const { error: storageError } = await deleteFile(doc.file_path)
  if (storageError) {
    console.error('Storage delete failed:', storageError)
    // Continue with DB delete even if storage fails
  }

  // Delete from database
  const { error: dbError } = await supabase
    .from('documents')
    .delete()
    .eq('id', documentId)

  if (dbError) {
    return { error: dbError.message }
  }

  revalidatePath('/documents')
  return { success: true }
}

export async function getDocuments() {
  const supabase = await createClient()

  const { data: { user } } = await supabase.auth.getUser()
  if (!user) {
    return { error: 'Not authenticated', data: [] }
  }

  const { data, error } = await supabase
    .from('documents')
    .select('*')
    .order('created_at', { ascending: false })

  if (error) {
    return { error: error.message, data: [] }
  }

  return { data: data || [], error: null }
}
```

Important implementation notes:
- The upload action uses fire-and-forget pattern for n8n webhook (no await) to avoid blocking the upload response.
- The n8n webhook URL is `/get-documents` per the existing webhook endpoint list in PROJECT.md.
- File path format is `{userId}/{timestamp}-{originalName}` which matches the RLS policy checking `(storage.foldername(name))[1] = auth.uid()::text`.
- Rollback pattern: if DB insert fails after storage upload, the uploaded file is deleted to prevent orphans.
- The `getDocuments` query relies on existing RLS policies on the `documents` table (already created in Phase 1 migration).
  </action>
  <verify>
1. Verify the migration was applied: run `SELECT * FROM storage.buckets WHERE id = 'documents';` via Supabase MCP execute_sql.
2. Verify storage policies exist: run `SELECT policyname FROM pg_policies WHERE tablename = 'objects' AND schemaname = 'storage';` via execute_sql.
3. Verify `lib/supabase/storage.ts` exports: check file exists and contains `uploadFile`, `deleteFile`, `getDocumentSignedUrl`.
4. Verify `app/(dashboard)/documents/actions.ts` exists and contains `'use server'` directive, `uploadDocument`, `deleteDocument`, `getDocuments`.
5. Run `npm run build` to confirm no TypeScript errors.
  </verify>
  <done>Supabase Storage bucket 'documents' exists with RLS policies for upload/view/delete. Storage helper at lib/supabase/storage.ts exports uploadFile, deleteFile, getDocumentSignedUrl. Document server actions at app/(dashboard)/documents/actions.ts export uploadDocument (with validation, rollback, and n8n webhook trigger), deleteDocument, and getDocuments. Build passes.</done>
</task>

</tasks>

<verification>
1. `npm ls @tiptap/react @tanstack/react-table` resolves all packages
2. `npm run build` completes without errors
3. Supabase Storage bucket 'documents' exists (private, RLS enabled)
4. Storage RLS policies exist for INSERT, SELECT, DELETE operations
5. `lib/supabase/storage.ts` contains three exported helper functions
6. `app/(dashboard)/documents/actions.ts` contains server actions with 'use server' directive
</verification>

<success_criteria>
- All Phase 3 npm dependencies installed and importable
- Supabase Storage bucket 'documents' created with correct RLS policies
- Storage helper utilities provide upload, delete, and signed URL generation
- Document server actions handle upload (with validation + rollback), delete, and listing
- Upload action triggers n8n categorization webhook fire-and-forget
- `npm run build` passes with zero errors
</success_criteria>

<output>
After completion, create `.planning/phases/03-document-vault-narrative-library/03-01-SUMMARY.md`
</output>
